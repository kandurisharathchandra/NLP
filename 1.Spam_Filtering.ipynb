{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtTsKOJ52rrX"
      },
      "source": [
        "# **NLP in practice: Spam filtering**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Machine learning pipeline**"
      ],
      "metadata": {
        "id": "DXOBSrJuTkhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n"
      ],
      "metadata": {
        "id": "DHDDIsGY-xHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Spam vs Ham\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAL7G7jr47x6",
        "outputId": "e514cb64-2393-457a-841a-292f55277bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1DNTg5rmIi5KpB0bz6_d7aAwWfxsfpGzU/Spam vs Ham\n",
            "\u001b[0m\u001b[01;34menron1\u001b[0m/  \u001b[01;34menron2\u001b[0m/  NLP_1.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in cell this we are trying to access the data available in my drive using drive library and by giving permission"
      ],
      "metadata": {
        "id": "aPCg_rdQ8z5s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t2l6Sy62rrY"
      },
      "source": [
        "Read in spam and ham file lists:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-jsp7bk2rrY"
      },
      "outputs": [],
      "source": [
        "import os   # Using os functionality, list all the files in the specified folder.\n",
        "import codecs # helps with different text encodings.\n",
        "\n",
        "def read_in(folder):\n",
        "    files = os.listdir(folder)\n",
        "    a_list = []\n",
        "    for a_file in files:      # Iterate through the files in the folder.\n",
        "        if not a_file.startswith(\".\"):    # Skip hidden files\n",
        "            # Read the contents of each file.\n",
        "            f = codecs.open(folder + a_file, \"r\", encoding = \"ISO-8859-1\", errors=\"ignore\")\n",
        "            # Add the content of each file to the list data structure.\n",
        "            a_list.append(f.read())\n",
        "            f.close() # Close the file after you read the contents.\n",
        "    return a_list   # Return Python list that contains the contents of the files from the specified folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWzLQ4ox2rrZ"
      },
      "source": [
        "Initialise lists and print out length â€“ this should return 1500 for `enron1/spam` and 3672 for `enron1/ham`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lzfVVLx2rrZ",
        "outputId": "d06a2752-e0be-4b1f-d7ab-194091ec7ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500\n",
            "Subject: real teens love make sex (tons of video)\r\n",
            "Beautiful teen girls, erotic angels, sweet european girls, nasty blowjobs,\r\n",
            "Vivid face cumshots, teen defloration, rough throat fuck, hot college lesbians,\r\n",
            "Deep anal sex, coeds group hardcore and more! Only fresh and exclusive teen\r\n",
            "Photo and video content at teen mega portal!\r\n",
            "All inside!\r\n",
            "Remove your email\n",
            "3672\n",
            "Subject: re: equistar noms\n",
            "Julie\n",
            "I don' t have the deal numbers as I did not do the deals.... They were done by craig breslau....\n",
            "I can only suggest that you get with darren farmer to get the deal numbers\n",
            "Lee\n",
            "From: juliann kemp/enron@ enronxgate on 04/30/2001 02: 57 pm\n",
            "To: lee l papayoti/hou/ect@ ect\n",
            "Cc:\n",
            "Subject: equistar noms\n",
            "Lee - can you please give me the deal numbers so I can confirm the deals with equistar.\n",
            "Thanks - julie 713 - 345 - 8639\n",
            "Equistar\n",
            "D 1373 channel 10 greater of 4. 07 or 1 -. 20\n",
            "D 1373 channel 5 greater of 3. 30 or 1 -. 20\n",
            "D 1373 channel 2 greater of 2. 20 or 1 -. 05\n",
            "D 8024 bayport polymers 3 greater of 2. 20 or 1 -. 05\n",
            "D 1399 matagorda polymars 4 greater of 2. 20 or 1 -. 05\n",
            "D 1552 qel@ laporte 5 greater of 2. 68 or 1 -. 10\n",
            "D 1552 qel@ laporte 5 greater of 3. 30 or 1 -. 20\n",
            "D 1062 port arthur 1 greater of 2. 20 or 1 -. 05\n",
            "D 1384 chocolate bayou 10 greater of 2. 23 or 1 -. 05\n",
            "Subtotal 45\n",
            "Third party\n",
            "1373\n",
            "Phllips 3 deal #762340\n",
            "Sempra 15\n",
            "N. E. T. 10\n",
            "1552\n",
            "Morgan and stanley 5\n",
            "Sub total 33\n",
            "Grand total 78\n"
          ]
        }
      ],
      "source": [
        "spam_list = read_in(\"enron1/spam/\")\n",
        "print(len(spam_list))\n",
        "# Print out the contents of the first entry (i.e., the first file in each correspondent subfolder).\n",
        "print(spam_list[0])\n",
        "\n",
        "ham_list = read_in(\"enron1/ham/\")\n",
        "print(len(ham_list))\n",
        "# Print out the contents of the first entry (i.e., the first file in each correspondent subfolder).\n",
        "print(ham_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guiKT1DH2rrZ",
        "outputId": "f7d9d951-4681-4265-b763-66861d8bc1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size = 5172 emails\n"
          ]
        }
      ],
      "source": [
        "import random #importing random library\n",
        "\n",
        "all_emails = [(email_content, \"spam\") for email_content in spam_list]#creates tuples from spam_list where each email content is labeled as \"spam\".\n",
        "all_emails += [(email_content, \"ham\") for email_content in ham_list]#combines previous spam emails and creates tuples from ham_list where each email content is labeled as \"ham\".\n",
        "random.seed(42)#ensures reproducibility\n",
        "random.shuffle(all_emails)#shuffles the dataset mixes ham and spam mails.\n",
        "print (f\"Dataset size = {str(len(all_emails))} emails\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Split the text into words\n",
        "\n",
        "Preprocess the texts by tokenising them and removing the stopwords"
      ],
      "metadata": {
        "id": "wFJxTSD7ZCND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is important otherwise NLTK library was producing errors\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEB1wipROZxV",
        "outputId": "793f14c5-a9e1-4534-dea5-d28926f0ca82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK is imported, and word_tokenize is used for breaking text into words."
      ],
      "metadata": {
        "id": "AE0dKH9SBAX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "WHRDApKi2rra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c12d10-5220-4b36-a390-ba48c9254e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'participate': True, 'in': True, 'our': True, 'new': True, 'lottery': True, 'now': True, '!': True}\n",
            "5172\n",
            "203\n",
            "18\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "#NLTK is imported, and word_tokenize is used for breaking text into words.\n",
        "def get_features(text):   #function extracts all the features of text\n",
        "    features = {}         #it creates a dictionary named features\n",
        "    word_list = [word for word in word_tokenize(text.lower())] #Converts the text to lowercase (text.lower()).Tokenizes the text into words using word_tokenize.\n",
        "    for word in word_list:\n",
        "        features[word] = True #Adds each unique word as a key in the features dictionary with the value True.\n",
        "    return features\n",
        "\n",
        "all_features = [(get_features(email), label) for (email, label) in all_emails] #\n",
        "\n",
        "print(get_features(\"Participate In Our New Lottery NOW!\"))\n",
        "print(len(all_features))\n",
        "print(len(all_features[0][0]))\n",
        "print(len(all_features[99][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converts the dataset (all_emails) into a list of feature-label pairs.\n",
        "For each email:\n",
        "get_features(email) generates a dictionary of word features.\n",
        "The label (spam or ham) remains unchanged."
      ],
      "metadata": {
        "id": "ddK2Hl8PA2HQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Extract and normalize the features\n",
        "\n"
      ],
      "metadata": {
        "id": "U3d43gW-aM3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Train a classifier\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uFCAvEmHa7yK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF-1j8Zl2rra"
      },
      "source": [
        "Apply Naive Bayes classifier:\n",
        "The code trains a Naive Bayes classifier using the all_features dataset to classify emails as either spam or ham.\n",
        "features: The dataset of features and labels (e.g., all_features).\n",
        "proportion: The fraction of data to use for training (e.g., 0.8 for an 80-20 split).\n",
        "Splits the dataset into training (train_set) and testing (test_set).\n",
        "Trains a Naive Bayes classifier using the training set.\n",
        "train_set: Training dataset.\n",
        "test_set: Testing dataset.\n",
        "classifier: Trained Naive Bayes model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5wZNa4p2rra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4c0989-baf7-42fa-defe-236150122095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size = 4137 emails\n",
            "Test set size = 1035 emails\n"
          ]
        }
      ],
      "source": [
        "from nltk import NaiveBayesClassifier, classify\n",
        "\n",
        "def train(features, proportion):   #The fraction of data to use for training\n",
        "    train_size = int(len(features) * proportion)\n",
        "    # initialise the training and test sets\n",
        "    train_set, test_set = features[:train_size], features[train_size:]\n",
        "    print (f\"Training set size = {str(len(train_set))} emails\")\n",
        "    print (f\"Test set size = {str(len(test_set))} emails\")\n",
        "    # train the classifier\n",
        "    classifier = NaiveBayesClassifier.train(train_set)\n",
        "    return train_set, test_set, classifier\n",
        "\n",
        "train_set, test_set, classifier = train(all_features, 0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3NlG47X2rra"
      },
      "source": [
        "### Step 5: Evaluate the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDFIPBmZ2rra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacade21-7a85-4cd8-9f36-eab032ed5fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the training set = 0.9659173313995649\n",
            "Accuracy on the test set = 0.9555555555555556\n",
            "Most Informative Features\n",
            "                    2004 = True             spam : ham    =    130.9 : 1.0\n",
            "            prescription = True             spam : ham    =    121.3 : 1.0\n",
            "                     nom = True              ham : spam   =    121.1 : 1.0\n",
            "                    pain = True             spam : ham    =     97.2 : 1.0\n",
            "                  farmer = True              ham : spam   =     86.7 : 1.0\n",
            "                     sex = True             spam : ham    =     85.9 : 1.0\n",
            "                    spam = True             spam : ham    =     85.9 : 1.0\n",
            "                    2001 = True              ham : spam   =     77.9 : 1.0\n",
            "                     ect = True              ham : spam   =     75.0 : 1.0\n",
            "                  weight = True             spam : ham    =     74.7 : 1.0\n",
            "                  differ = True             spam : ham    =     69.9 : 1.0\n",
            "              nomination = True              ham : spam   =     68.8 : 1.0\n",
            "                      ex = True             spam : ham    =     68.3 : 1.0\n",
            "                creative = True             spam : ham    =     66.7 : 1.0\n",
            "                featured = True             spam : ham    =     66.7 : 1.0\n",
            "             medications = True             spam : ham    =     66.7 : 1.0\n",
            "                   adobe = True             spam : ham    =     61.8 : 1.0\n",
            "                    2005 = True             spam : ham    =     57.3 : 1.0\n",
            "                congress = True             spam : ham    =     57.0 : 1.0\n",
            "                  sexual = True             spam : ham    =     57.0 : 1.0\n",
            "                    sony = True             spam : ham    =     57.0 : 1.0\n",
            "             legislation = True             spam : ham    =     53.8 : 1.0\n",
            "                     pro = True             spam : ham    =     53.8 : 1.0\n",
            "                   cisco = True             spam : ham    =     52.2 : 1.0\n",
            "                inherent = True             spam : ham    =     52.2 : 1.0\n",
            "                   cheap = True             spam : ham    =     50.6 : 1.0\n",
            "                    draw = True             spam : ham    =     49.0 : 1.0\n",
            "                      cc = True              ham : spam   =     48.8 : 1.0\n",
            "                  health = True             spam : ham    =     47.7 : 1.0\n",
            "                  unique = True             spam : ham    =     47.4 : 1.0\n",
            "                     tap = True              ham : spam   =     45.8 : 1.0\n",
            "                 doctors = True             spam : ham    =     45.8 : 1.0\n",
            "                   penis = True             spam : ham    =     45.8 : 1.0\n",
            "                 foresee = True             spam : ham    =     44.2 : 1.0\n",
            "                 advises = True             spam : ham    =     42.6 : 1.0\n",
            "                  symbol = True             spam : ham    =     41.0 : 1.0\n",
            "              compliance = True             spam : ham    =     40.3 : 1.0\n",
            "                   steve = True              ham : spam   =     40.3 : 1.0\n",
            "                 generic = True             spam : ham    =     40.0 : 1.0\n",
            "                    lisa = True              ham : spam   =     39.4 : 1.0\n",
            "                   susan = True              ham : spam   =     39.2 : 1.0\n",
            "                 charset = True             spam : ham    =     37.7 : 1.0\n",
            "                     fat = True             spam : ham    =     37.7 : 1.0\n",
            "                powerful = True             spam : ham    =     37.7 : 1.0\n",
            "                   risks = True             spam : ham    =     37.1 : 1.0\n",
            "                       u = True             spam : ham    =     36.8 : 1.0\n",
            "                     ibm = True             spam : ham    =     36.1 : 1.0\n",
            "                      se = True             spam : ham    =     36.1 : 1.0\n",
            "                     bob = True              ham : spam   =     35.9 : 1.0\n",
            "               clearance = True             spam : ham    =     35.2 : 1.0\n"
          ]
        }
      ],
      "source": [
        "def evaluate(train_set, test_set, classifier):\n",
        "    # check how the classifier performs on the training and test sets\n",
        "    print (f\"Accuracy on the training set = {str(classify.accuracy(classifier, train_set))}\")\n",
        "    print (f\"Accuracy on the test set = {str(classify.accuracy(classifier, test_set))}\")\n",
        "    # check which words are most informative for the classifier\n",
        "    classifier.show_most_informative_features(50)\n",
        "\n",
        "evaluate(train_set, test_set, classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_set: The training dataset (used to train the model).\n",
        "test_set: The testing dataset (used to evaluate the model's generalization).\n",
        "classifier: The trained Naive Bayes classifier.\n",
        "Calculates and prints the accuracy of the classifier on the training set and the test set.\n",
        "The classify.accuracy() function compares the classifier's predictions to the actual labels in the dataset.\n",
        "Displays the top 50 words (features) that are most informative for distinguishing between spam and ham.\n",
        "This helps to understand which words the model finds most significant for classification."
      ],
      "metadata": {
        "id": "Pu1II9AfEiKk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ5nANxU2rra"
      },
      "source": [
        "Explore the contexts of use:\n",
        "Input some of your own messages:\n",
        "test_spam_list contains sample spam emails.\n",
        "test_ham_list contains sample ham (non-spam) emails.\n",
        "These are combined into test_emails as a list of tuples (email_content, label).\n",
        "Converts each email in test_emails into its feature representation using the get_features function.\n",
        "new_test_set is a list of feature-label pairs, ready to be used for evaluation.\n",
        "Tests the classifier's performance on the manually created new_test_set.\n",
        "The function prints:\n",
        "Accuracy of the classifier on the training set (train_set).\n",
        "Accuracy on the new test set (new_test_set).\n",
        "The 50 most informative features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5Iv6RyK2rra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3107b4e0-7d4f-4bd6-f117-64f86b081b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STOCKS in HAM:\n",
            "Displaying 1 of 1 matches:\n",
            "ur member directory . * follow your stocks and news headlines , exchange files\n",
            "Displaying 1 of 1 matches:\n",
            "ur member directory . * follow your stocks and news headlines , exchange files\n",
            "Displaying 1 of 1 matches:\n",
            "ur member directory . * follow your stocks and news headlines , exchange files\n",
            "Displaying 1 of 1 matches:\n",
            "ad my portfolio is diversified into stocks that have lost even more money than\n",
            "\n",
            "\n",
            "STOCKS in SPAM:\n",
            "Displaying 1 of 1 matches:\n",
            "    subject : fwd : screw doctors . stocks available . vlagr @ . x _ a _ nax .\n",
            "Displaying 1 of 1 matches:\n",
            "cautions that small and micro - cap stocks are high - risk investments and tha\n",
            "Displaying 1 of 1 matches:\n",
            "s obtained . investing in micro cap stocks is extremely risky and , investors \n",
            "Displaying 2 of 2 matches:\n",
            "ims and do your own due diligence . stocks to play ( s 2 p ) profiles are not \n",
            "s obtained . investing in micro cap stocks is extremely risky and , investors \n",
            "Displaying 2 of 2 matches:\n",
            "rt identifying defense and security stocks ready to explode look at the moves \n",
            " actual exchanges where small - cap stocks are traded . silica stopband doorkn\n",
            "Displaying 3 of 3 matches:\n",
            " statements . as with many microcap stocks , todays company has additional ris\n",
            "blication pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this publication . \n",
            "Displaying 5 of 5 matches:\n",
            "5 where were you when the following stocks exploded : scos : exploded from . 3\n",
            "d . 80 on friday . face it . little stocks can mean big gains for you . this r\n",
            "might occur . as with many microcap stocks , today ' s company has additional \n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 3 of 3 matches:\n",
            " statements . as with many microcap stocks , todays company has additional ris\n",
            "blication pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this publication . \n",
            "Displaying 1 of 1 matches:\n",
            "fessionally not multi - level - not stocks - not real estate no cost tele - se\n",
            "Displaying 2 of 2 matches:\n",
            "ng their gains . select gold mining stocks are the hot flyers of the otc . his\n",
            "is letter cautions that micro - cap stocks are high - risk investments and tha\n",
            "Displaying 4 of 4 matches:\n",
            "y agree , some , not all , of these stocks move in price because they are prom\n",
            "tands or that as with many microcap stocks , today ' s company has additional \n",
            "is report pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 6 of 6 matches:\n",
            " if you knew about these low priced stocks : otcbb : zapz : closed march 31 st\n",
            " following points : * many of these stocks are undiscovered and uncovered ! wh\n",
            " ! ! * * many of these undiscovered stocks are like coiled springs , wound tig\n",
            "might occur . as with many microcap stocks , today ' s company has additional \n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 4 of 4 matches:\n",
            "hree days . play of the week tracks stocks on downward trends , foresees botto\n",
            "mark is our uncanny ability to spot stocks that have bottomed - out and antici\n",
            "ound and upward trend . most of the stocks we track rebound and peak within ju\n",
            "om third party . investing in penny stocks is high risk and you should seek pr\n",
            "Displaying 6 of 6 matches:\n",
            "hem : ( big money was made in these stocks by savvy investors who timed them r\n",
            "g filthy , stinking ri ' ch in tiny stocks no one has ever heard of until now \n",
            "ynamic things . some of these small stocks have absolutely exploded in price r\n",
            "'' occur . as with many micro - cap stocks , today ' s company has additional \n",
            " ema - il pertaining to investing , stocks or securities must be understood as\n",
            "ntative before deciding to trade in stocks featured within this ema - il . non\n",
            "Displaying 4 of 4 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "eep in mind that when trading small stocks like the company above there is a c\n",
            "t professional before investing any stocks or mutual funds .\n",
            "Displaying 1 of 1 matches:\n",
            "cautions that small and micro - cap stocks are high - risk investments and tha\n",
            "Displaying 3 of 3 matches:\n",
            "ancements but may be one of the few stocks left in this industry group that is\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 4 of 4 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "eep in mind that when trading small stocks like the company above there is a c\n",
            "t professional before investing any stocks or mutual funds .\n",
            "Displaying 1 of 1 matches:\n",
            "in apple investments , inc profiled stocks . in order to be in full compliance\n",
            "Displaying 1 of 1 matches:\n",
            "ecializing in undervalued small cap stocks for immediate breakout erhc and exx\n",
            "Displaying 3 of 3 matches:\n",
            "torage inc. play of the week tracks stocks on downward trends , foresees botto\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 2 of 2 matches:\n",
            "is emai | pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 3 of 3 matches:\n",
            "might occur . as with many microcap stocks , today ' s company has additional \n",
            "is emai | pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this emai | . none \n",
            "Displaying 2 of 2 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this emai | . none \n",
            "Displaying 2 of 2 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 3 of 3 matches:\n",
            "might occur . as with many microcap stocks , today ' s company has additiona |\n",
            "is emai | pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this emai | . none \n",
            "Displaying 3 of 3 matches:\n",
            " plays . widespread gains in energy stocks are inflating the portfolios of agg\n",
            "st levels of the year , with energy stocks outperforming all other market sect\n",
            "utions that sma | | and micro - cap stocks are high - risk investments and tha\n",
            "Displaying 2 of 2 matches:\n",
            " % on regular price we have massive stocks of drugs for same day dispatch fast\n",
            "e do have the lowest price and huge stocks ready for same - day dispatch . two\n",
            "Displaying 2 of 2 matches:\n",
            " % on regular price we have massive stocks of drugs for same day dispatch fast\n",
            "e do have the lowest price and huge stocks ready for same - day dispatch . two\n",
            "Displaying 3 of 3 matches:\n",
            " statements . as with many microcap stocks , today ' s company has additiona |\n",
            "is report pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 2 of 2 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 2 of 2 matches:\n",
            "                    subject : penny stocks are about timing nomad internationa\n",
            " one trade friday ! go ndin . penny stocks are considered highiy speculative a\n",
            "Displaying 1 of 1 matches:\n",
            " one trade monday ! go wysk . penny stocks are considered highiy specuiative a\n",
            "Displaying 2 of 2 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 4 of 4 matches:\n",
            "watch this one trade . these little stocks can surprise in a big way sometimes\n",
            "might occur . as with many microcap stocks , today ' s company has additional \n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 3 of 3 matches:\n",
            "report reveals this smallcap rocket stocks newsletter first we would like to s\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 1 of 1 matches:\n",
            "dge - ksige are you tired of buying stocks and not having them perform ? our s\n",
            "Displaying 4 of 4 matches:\n",
            "ck monday some of these little voip stocks have been rea | | y moving lately .\n",
            " statements . as with many microcap stocks , today ' s company has additiona |\n",
            "is report pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 2 of 2 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 1 of 1 matches:\n",
            "or information puposes only . penny stocks are considered highly speculative a\n",
            "Displaying 1 of 1 matches:\n",
            " one trade monday ! go wysk . penny stocks are considered highiy specuiative a\n",
            "Displaying 4 of 4 matches:\n",
            "k tuesday some of these littie voip stocks have been reaily moving lateiy . an\n",
            " statements . as with many microcap stocks , today ' s company has additional \n",
            "is report pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 2 of 2 matches:\n",
            " the last 12 months , many of these stocks made tripie and even quadruple retu\n",
            "one trade tuesday ! go mogi . penny stocks are considered highly speculative a\n",
            "Displaying 5 of 5 matches:\n",
            "ck monday some of these littie voip stocks have been really moving lately . an\n",
            "t can happen with these sma | | cap stocks when they take off . and it happens\n",
            " statements . as with many microcap stocks , today ' s company has additiona |\n",
            "is report pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 2 of 2 matches:\n",
            " % on regular price we have massive stocks of drugs for same day dispatch fast\n",
            "e do have the lowest price and huge stocks ready for same - day dispatch . two\n",
            "Displaying 5 of 5 matches:\n",
            "hursday ! some of these littie voip stocks have been realiy moving lateiy . an\n",
            "t can happen with these sma | | cap stocks when they take off . and it happens\n",
            " statements . as with many microcap stocks , today ' s company has additiona |\n",
            "is report pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 2 of 2 matches:\n",
            "ck monday some of these little voip stocks have been really moving lately . an\n",
            " one trade monday ! go ypil . penny stocks are considered highiy specuiative a\n",
            "Displaying 3 of 3 matches:\n",
            "n how many times have you seen good stocks but you couldn ' t get your hands o\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 1 of 1 matches:\n",
            " receive first notice on run - away stocks traders ' monthly alert january pic\n",
            "Displaying 3 of 3 matches:\n",
            "might occur . as with many microcap stocks , today ' s company has additiona |\n",
            "is emai | pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 4 of 4 matches:\n",
            " the last 12 months , many of these stocks made triple and even quadruple retu\n",
            " statements . as with many microcap stocks , today ' s company has additiona |\n",
            "is report pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this report . none \n",
            "Displaying 4 of 4 matches:\n",
            "tion is key to stock success rocket stocks newsletter u r g e n t i n v e s t \n",
            "ht occur . as with many micro - cap stocks , today ' s company has additional \n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 3 of 3 matches:\n",
            "5 how many times have you seen good stocks but you couldn ' t get your hands o\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 2 of 2 matches:\n",
            "ck monday some of these little voip stocks have been realiy moving lately . an\n",
            " one trade monday ! go ypil . penny stocks are considered highiy specuiative a\n",
            "Displaying 1 of 1 matches:\n",
            "ne trade thursday ! go fcdh . penny stocks are considered highiy specuiative a\n",
            "Displaying 1 of 1 matches:\n",
            "scovering value in natural resource stocks elgin resources ( elr - tsx ) extra\n",
            "Displaying 1 of 1 matches:\n",
            " one trade monday ! go wysk . penny stocks are considered highiy speculative a\n",
            "Displaying 1 of 1 matches:\n",
            " one trade monday ! go ndin . penny stocks are considered highly speculative a\n",
            "Displaying 1 of 1 matches:\n",
            "the | ast 12 months , many of these stocks made triple and even quadruple retu\n",
            "Displaying 1 of 1 matches:\n",
            " the last 12 months , many of these stocks made tripie and even quadruple retu\n",
            "Displaying 3 of 3 matches:\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            " lose money from investing in penny stocks . if you wish to stop future mailin\n",
            "Displaying 3 of 3 matches:\n",
            "might occur . as with many microcap stocks , today ' s company has additiona |\n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 4 of 4 matches:\n",
            "n this stock . some of these smal | stocks are absoiuteiy fiying , as many of \n",
            " statements . as with many microcap stocks , todays company has additional ris\n",
            "biication pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this publication . \n",
            "Displaying 3 of 3 matches:\n",
            "might occur . as with many microcap stocks , today ' s company has additiona |\n",
            "is emai | pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            "Displaying 4 of 4 matches:\n",
            "nt opportunity drummond , small cap stocks alert newsletter must read - alert \n",
            "his email pertaining to investing , stocks , securities must be understood as \n",
            "ntative before deciding to trade in stocks featured within this email . none o\n",
            " lose money from investing in penny stocks . - - - - - - - - - - - - - - - - -\n",
            "Displaying 1 of 1 matches:\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ penny - stocks are considered highly speculative a\n"
          ]
        }
      ],
      "source": [
        "from nltk.text import Text\n",
        "\n",
        "def concordance(data_list, search_word):\n",
        "    for email in data_list:\n",
        "        word_list = [word for word in word_tokenize(email.lower())]\n",
        "        text_list = Text(word_list)\n",
        "        if search_word in word_list:\n",
        "            text_list.concordance(search_word)\n",
        "\n",
        "\n",
        "print (\"STOCKS in HAM:\")\n",
        "concordance(ham_list, \"stocks\")\n",
        "print (\"\\n\\nSTOCKS in SPAM:\")\n",
        "concordance(spam_list, \"stocks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB9CCJqp2rrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2994ce-24fe-4fc0-8fe4-8be52cb01731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the training set = 0.9659173313995649\n",
            "Accuracy on the test set = 1.0\n",
            "Most Informative Features\n",
            "                    2004 = True             spam : ham    =    130.9 : 1.0\n",
            "            prescription = True             spam : ham    =    121.3 : 1.0\n",
            "                     nom = True              ham : spam   =    121.1 : 1.0\n",
            "                    pain = True             spam : ham    =     97.2 : 1.0\n",
            "                  farmer = True              ham : spam   =     86.7 : 1.0\n",
            "                     sex = True             spam : ham    =     85.9 : 1.0\n",
            "                    spam = True             spam : ham    =     85.9 : 1.0\n",
            "                    2001 = True              ham : spam   =     77.9 : 1.0\n",
            "                     ect = True              ham : spam   =     75.0 : 1.0\n",
            "                  weight = True             spam : ham    =     74.7 : 1.0\n",
            "                  differ = True             spam : ham    =     69.9 : 1.0\n",
            "              nomination = True              ham : spam   =     68.8 : 1.0\n",
            "                      ex = True             spam : ham    =     68.3 : 1.0\n",
            "                creative = True             spam : ham    =     66.7 : 1.0\n",
            "                featured = True             spam : ham    =     66.7 : 1.0\n",
            "             medications = True             spam : ham    =     66.7 : 1.0\n",
            "                   adobe = True             spam : ham    =     61.8 : 1.0\n",
            "                    2005 = True             spam : ham    =     57.3 : 1.0\n",
            "                congress = True             spam : ham    =     57.0 : 1.0\n",
            "                  sexual = True             spam : ham    =     57.0 : 1.0\n",
            "                    sony = True             spam : ham    =     57.0 : 1.0\n",
            "             legislation = True             spam : ham    =     53.8 : 1.0\n",
            "                     pro = True             spam : ham    =     53.8 : 1.0\n",
            "                   cisco = True             spam : ham    =     52.2 : 1.0\n",
            "                inherent = True             spam : ham    =     52.2 : 1.0\n",
            "                   cheap = True             spam : ham    =     50.6 : 1.0\n",
            "                    draw = True             spam : ham    =     49.0 : 1.0\n",
            "                      cc = True              ham : spam   =     48.8 : 1.0\n",
            "                  health = True             spam : ham    =     47.7 : 1.0\n",
            "                  unique = True             spam : ham    =     47.4 : 1.0\n",
            "                     tap = True              ham : spam   =     45.8 : 1.0\n",
            "                 doctors = True             spam : ham    =     45.8 : 1.0\n",
            "                   penis = True             spam : ham    =     45.8 : 1.0\n",
            "                 foresee = True             spam : ham    =     44.2 : 1.0\n",
            "                 advises = True             spam : ham    =     42.6 : 1.0\n",
            "                  symbol = True             spam : ham    =     41.0 : 1.0\n",
            "              compliance = True             spam : ham    =     40.3 : 1.0\n",
            "                   steve = True              ham : spam   =     40.3 : 1.0\n",
            "                 generic = True             spam : ham    =     40.0 : 1.0\n",
            "                    lisa = True              ham : spam   =     39.4 : 1.0\n",
            "                   susan = True              ham : spam   =     39.2 : 1.0\n",
            "                 charset = True             spam : ham    =     37.7 : 1.0\n",
            "                     fat = True             spam : ham    =     37.7 : 1.0\n",
            "                powerful = True             spam : ham    =     37.7 : 1.0\n",
            "                   risks = True             spam : ham    =     37.1 : 1.0\n",
            "                       u = True             spam : ham    =     36.8 : 1.0\n",
            "                     ibm = True             spam : ham    =     36.1 : 1.0\n",
            "                      se = True             spam : ham    =     36.1 : 1.0\n",
            "                     bob = True              ham : spam   =     35.9 : 1.0\n",
            "               clearance = True             spam : ham    =     35.2 : 1.0\n"
          ]
        }
      ],
      "source": [
        "test_spam_list = [\"Participate in our new lottery!\", \"Try out this new medicine\"]\n",
        "test_ham_list = [\"See the minutes from the last meeting attached\",\n",
        "                 \"Investors are coming to our office on Monday\"]\n",
        "\n",
        "test_emails = [(email_content, \"spam\") for email_content in test_spam_list]\n",
        "test_emails += [(email_content, \"ham\") for email_content in test_ham_list]\n",
        "\n",
        "new_test_set = [(get_features(email), label) for (email, label) in test_emails]\n",
        "\n",
        "evaluate(train_set, new_test_set, classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bWj93ja2rrb"
      },
      "source": [
        "See how they get classified:\n",
        "Iterates through each email in test_spam_list.\n",
        "Uses the get_features(email) function to convert the email into its feature representation.\n",
        "Passes the features to the classifier.classify() method, which predicts whether the email is spam or ham.\n",
        "Prints the email content and its predicted label.\n",
        "\n",
        "The classifier.classify() method predicts the label (spam or ham) based on the features extracted from the email.\n",
        "If your model is well-trained, it should correctly classify all test emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqiHT7K62rrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f913df-de87-4030-9cb2-4fd7f9d9320a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Participate in our new lottery!\n",
            "spam\n",
            "Try out this new medicine\n",
            "spam\n",
            "See the minutes from the last meeting attached\n",
            "ham\n",
            "Investors are coming to our office on Monday\n",
            "ham\n"
          ]
        }
      ],
      "source": [
        "for email in test_spam_list:\n",
        "    print (email)\n",
        "    print (classifier.classify(get_features(email)))\n",
        "for email in test_ham_list:\n",
        "    print (email)\n",
        "    print (classifier.classify(get_features(email)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DOwXAK22rrb"
      },
      "source": [
        "Run in an interactive manner:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZQhBR802rrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914608c3-1fec-4a03-a6ab-306b6b58d3db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type in your email here (or press 'Enter'): \n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    email = input(\"Type in your email here (or press 'Enter'): \")\n",
        "    if len(email)==0:\n",
        "        break\n",
        "    else:\n",
        "        prediction = classifier.classify(get_features(email))\n",
        "        print (f\"This email is likely {prediction}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9JkmwYj2rrb"
      },
      "source": [
        "Run on a different dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDG_vDp92rrb"
      },
      "source": [
        "# Assignment:\n",
        "\n",
        "Apply the classifier to a different test set, e.g. the emails from `enron2/`. As before, you need to read in the data, extract textual content, extract the features and evaluate the classifier.\n",
        "\n",
        "One of such publicly available collections is Enron email dataset. (You can read more about the dataset at www.cs.cmu.edu/~enron/, and download the subsets of the data at http://mng.bz/WxYg. The subsets and data collection process are described in more detail at http://www2.aueb.gr/users/ion/docs/ceas2006_paper.pdf.)\n",
        "\n",
        "This is a dataset of emails, including both ham (extracted from the original Enron dataset using personal messages of three Enron employees) and spam emails.\n",
        "\n",
        "What do the results tell you?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwPtfoka2rrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071198f8-1ae7-4ec7-d0d8-1b825a149db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1496\n",
            "Subject: the credit law is on your side jm! Get perfect credit now!\r\n",
            "I will show you how you can quickly and easily improve your credit to a perfect rating!\r\n",
            "Click here now for full free details!\r\n",
            "\n",
            "4361\n",
            "Subject: credit model status update\n",
            "Bill,\n",
            "I am forwarding a memo from vincent tang about the new credit model.\n",
            "English may be imperfect but the message is clear.\n",
            "Vince\n",
            "- - - - - - - - - - - - - - - - - - - - - - forwarded by vince j kaminski/hou/ect on 02/10/2000\n",
            "02: 31 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "Vincent tang\n",
            "02/08/2000 02: 43 pm\n",
            "To: vince j kaminski/hou/ect@ ect, grant masson/hou/ect@ ect, tanya\n",
            "Tamarchenko/hou/ect@ ect\n",
            "Cc:\n",
            "Subject: credit model status update\n",
            "Accuracy on the training set = 0.9659173313995649\n",
            "Accuracy on the test set = 0.7766774799385351\n",
            "Most Informative Features\n",
            "                    2004 = True             spam : ham    =    130.9 : 1.0\n",
            "            prescription = True             spam : ham    =    121.3 : 1.0\n",
            "                     nom = True              ham : spam   =    121.1 : 1.0\n",
            "                    pain = True             spam : ham    =     97.2 : 1.0\n",
            "                  farmer = True              ham : spam   =     86.7 : 1.0\n",
            "                     sex = True             spam : ham    =     85.9 : 1.0\n",
            "                    spam = True             spam : ham    =     85.9 : 1.0\n",
            "                    2001 = True              ham : spam   =     77.9 : 1.0\n",
            "                     ect = True              ham : spam   =     75.0 : 1.0\n",
            "                  weight = True             spam : ham    =     74.7 : 1.0\n",
            "                  differ = True             spam : ham    =     69.9 : 1.0\n",
            "              nomination = True              ham : spam   =     68.8 : 1.0\n",
            "                      ex = True             spam : ham    =     68.3 : 1.0\n",
            "                creative = True             spam : ham    =     66.7 : 1.0\n",
            "                featured = True             spam : ham    =     66.7 : 1.0\n",
            "             medications = True             spam : ham    =     66.7 : 1.0\n",
            "                   adobe = True             spam : ham    =     61.8 : 1.0\n",
            "                    2005 = True             spam : ham    =     57.3 : 1.0\n",
            "                congress = True             spam : ham    =     57.0 : 1.0\n",
            "                  sexual = True             spam : ham    =     57.0 : 1.0\n",
            "                    sony = True             spam : ham    =     57.0 : 1.0\n",
            "             legislation = True             spam : ham    =     53.8 : 1.0\n",
            "                     pro = True             spam : ham    =     53.8 : 1.0\n",
            "                   cisco = True             spam : ham    =     52.2 : 1.0\n",
            "                inherent = True             spam : ham    =     52.2 : 1.0\n",
            "                   cheap = True             spam : ham    =     50.6 : 1.0\n",
            "                    draw = True             spam : ham    =     49.0 : 1.0\n",
            "                      cc = True              ham : spam   =     48.8 : 1.0\n",
            "                  health = True             spam : ham    =     47.7 : 1.0\n",
            "                  unique = True             spam : ham    =     47.4 : 1.0\n",
            "                     tap = True              ham : spam   =     45.8 : 1.0\n",
            "                 doctors = True             spam : ham    =     45.8 : 1.0\n",
            "                   penis = True             spam : ham    =     45.8 : 1.0\n",
            "                 foresee = True             spam : ham    =     44.2 : 1.0\n",
            "                 advises = True             spam : ham    =     42.6 : 1.0\n",
            "                  symbol = True             spam : ham    =     41.0 : 1.0\n",
            "              compliance = True             spam : ham    =     40.3 : 1.0\n",
            "                   steve = True              ham : spam   =     40.3 : 1.0\n",
            "                 generic = True             spam : ham    =     40.0 : 1.0\n",
            "                    lisa = True              ham : spam   =     39.4 : 1.0\n",
            "                   susan = True              ham : spam   =     39.2 : 1.0\n",
            "                 charset = True             spam : ham    =     37.7 : 1.0\n",
            "                     fat = True             spam : ham    =     37.7 : 1.0\n",
            "                powerful = True             spam : ham    =     37.7 : 1.0\n",
            "                   risks = True             spam : ham    =     37.1 : 1.0\n",
            "                       u = True             spam : ham    =     36.8 : 1.0\n",
            "                     ibm = True             spam : ham    =     36.1 : 1.0\n",
            "                      se = True             spam : ham    =     36.1 : 1.0\n",
            "                     bob = True              ham : spam   =     35.9 : 1.0\n",
            "               clearance = True             spam : ham    =     35.2 : 1.0\n"
          ]
        }
      ],
      "source": [
        "test_spam_list = read_in(\"enron2/spam/\") #read spam files in enron2 folder\n",
        "print(len(test_spam_list))\n",
        "print(test_spam_list[0])\n",
        "test_ham_list = read_in(\"enron2/ham/\")#read ham files in enron2 folder\n",
        "print(len(test_ham_list))\n",
        "print(test_ham_list[0])\n",
        "\n",
        "test_emails = [(email_content, \"spam\") for email_content in test_spam_list]\n",
        "test_emails += [(email_content, \"ham\") for email_content in test_ham_list]\n",
        "random.shuffle(test_emails)\n",
        "\n",
        "new_test_set = [(get_features(email), label) for (email, label) in test_emails]\n",
        "\n",
        "evaluate(train_set, new_test_set, classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dahqL1VW2rrb"
      },
      "source": [
        "Combine the two datasets:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reads spam emails from the directory enron2/spam/ using the read_in() function.\n",
        "Prints the number of spam emails and the first spam email in the list.\n",
        "Reads ham emails from the directory enron2/ham/ using the read_in() function.\n",
        "Prints the number of ham emails and the first ham email in the list.\n",
        "Combines spam and ham emails into a single dataset of tuples: (email_content, label).\n",
        "Shuffles the dataset randomly to avoid any ordering bias during evaluation.\n",
        "Converts each email into a feature representation using the get_features() function.\n",
        "Prepares the dataset for evaluation by pairing features with labels.\n",
        "Evaluates the trained classifier on the new test set (new_test_set).\n",
        "Prints:\n",
        "Accuracy on the training set (train_set).\n",
        "Accuracy on the new test set (new_test_set).\n",
        "The most informative features."
      ],
      "metadata": {
        "id": "n0gEX9DTHPbh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJYU29bO2rrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6983227-5f45-4712-b01a-d4397629a735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2996\n",
            "8033\n",
            "11029\n",
            "Training set size = 8823 emails\n",
            "Test set size = 2206 emails\n",
            "Accuracy on the training set = 0.9820922588688654\n",
            "Accuracy on the test set = 0.9730237322861534\n",
            "Most Informative Features\n",
            "                   meter = True              ham : spam   =    264.5 : 1.0\n",
            "                    2004 = True             spam : ham    =    245.7 : 1.0\n",
            "                   vince = True              ham : spam   =    200.8 : 1.0\n",
            "                     nom = True              ham : spam   =    196.3 : 1.0\n",
            "                     sex = True             spam : ham    =    195.1 : 1.0\n",
            "                     ect = True              ham : spam   =    175.5 : 1.0\n",
            "            prescription = True             spam : ham    =    169.2 : 1.0\n",
            "                    spam = True             spam : ham    =    145.8 : 1.0\n",
            "               forwarded = True              ham : spam   =    135.7 : 1.0\n",
            "                     fyi = True              ham : spam   =    133.9 : 1.0\n",
            "              nomination = True              ham : spam   =    113.0 : 1.0\n",
            "                   corel = True             spam : ham    =    104.4 : 1.0\n",
            "                  dealer = True             spam : ham    =    104.4 : 1.0\n",
            "                 readers = True             spam : ham    =     96.6 : 1.0\n",
            "                  sexual = True             spam : ham    =     95.3 : 1.0\n",
            "                      cc = True              ham : spam   =     89.1 : 1.0\n",
            "                     pat = True              ham : spam   =     87.2 : 1.0\n",
            "                 shirley = True              ham : spam   =     83.8 : 1.0\n",
            "                    2005 = True             spam : ham    =     81.5 : 1.0\n",
            "              materially = True             spam : ham    =     79.7 : 1.0\n",
            "                     853 = True              ham : spam   =     79.4 : 1.0\n",
            "             medications = True             spam : ham    =     78.4 : 1.0\n",
            "                identity = True             spam : ham    =     75.8 : 1.0\n",
            "                   plain = True             spam : ham    =     74.5 : 1.0\n",
            "                     713 = True              ham : spam   =     74.1 : 1.0\n",
            "                  secret = True             spam : ham    =     73.2 : 1.0\n",
            "                   logos = True             spam : ham    =     72.7 : 1.0\n",
            "                   boost = True             spam : ham    =     70.4 : 1.0\n",
            "                   penis = True             spam : ham    =     69.4 : 1.0\n",
            "                 removal = True             spam : ham    =     69.4 : 1.0\n",
            "                      wi = True             spam : ham    =     69.4 : 1.0\n",
            "                 beliefs = True             spam : ham    =     68.1 : 1.0\n",
            "                 foresee = True             spam : ham    =     66.8 : 1.0\n",
            "                    pain = True             spam : ham    =     65.7 : 1.0\n",
            "                  studio = True             spam : ham    =     65.0 : 1.0\n",
            "               specially = True             spam : ham    =     64.2 : 1.0\n",
            "                   epson = True             spam : ham    =     61.6 : 1.0\n",
            "                featured = True             spam : ham    =     60.8 : 1.0\n",
            "            completeness = True             spam : ham    =     60.3 : 1.0\n",
            "                   lasts = True             spam : ham    =     57.7 : 1.0\n",
            "                   adult = True             spam : ham    =     55.1 : 1.0\n",
            "                 explode = True             spam : ham    =     55.1 : 1.0\n",
            "                thousand = True             spam : ham    =     53.8 : 1.0\n",
            "              scheduling = True              ham : spam   =     53.7 : 1.0\n",
            "                     apc = True             spam : ham    =     52.5 : 1.0\n",
            "                 lenders = True             spam : ham    =     52.5 : 1.0\n",
            "                   shops = True             spam : ham    =     51.2 : 1.0\n",
            "                     uae = True             spam : ham    =     51.2 : 1.0\n",
            "                inherent = True             spam : ham    =     50.9 : 1.0\n",
            "                  differ = True             spam : ham    =     50.8 : 1.0\n"
          ]
        }
      ],
      "source": [
        "spam_list = read_in(\"enron1/spam/\") + read_in(\"enron2/spam/\")\n",
        "print(len(spam_list))\n",
        "ham_list = read_in(\"enron1/ham/\") + read_in(\"enron2/ham/\")\n",
        "print(len(ham_list))\n",
        "\n",
        "all_emails = [(email_content, \"spam\") for email_content in spam_list]\n",
        "all_emails += [(email_content, \"ham\") for email_content in ham_list]\n",
        "random.shuffle(test_emails)\n",
        "\n",
        "all_features = [(get_features(email), label) for (email, label) in all_emails]\n",
        "print(len(all_features))\n",
        "\n",
        "train_set, test_set, classifier = train(all_features, 0.8)\n",
        "evaluate(train_set, new_test_set, classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spam_list: Combines spam emails from both enron1/spam/ and enron2/spam/ directories.\n",
        "ham_list: Combines ham emails from both enron1/ham/ and enron2/ham/ directories.\n",
        "The print() statements show the total number of spam and ham emails loaded.\n",
        "For each email in spam_list, associate the label \"spam\".\n",
        "For each email in ham_list, associate the label \"ham\".\n",
        "Add both lists together into the all_emails list.\n",
        "Shuffle all_emails to randomize the order of emails (this is important for evaluation to prevent ordering bias).\n",
        "Note: The variable test_emails seems to be used instead of all_emails in random.shuffle() â€” this is likely a typo, and it should be random.shuffle(all_emails).\n",
        "Converts each email in all_emails to its feature representation using the get_features() function.\n",
        "The resulting all_features list contains tuples of (features, label) for each email.\n",
        "Prints the number of feature-label pairs in all_features.\n",
        "Splits all_features into a training set (80% of the data) and a test set (20% of the data).\n",
        "Trains the Naive Bayes classifier using the training set.\n",
        "Returns the train_set, test_set, and the trained classifier.\n",
        "Evaluates the trained classifier on the new_test_set (which seems to be undefined in the provided code).\n",
        "This will calculate the accuracy on the training and testing datasets and show the most informative features used by the classifier."
      ],
      "metadata": {
        "id": "PESF2s-wH_Ex"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}